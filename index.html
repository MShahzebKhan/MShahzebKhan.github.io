<!DOCTYPE html>
<html>
<head>
<title>M.Shahzeb Khan Gul</title>
<style>
body {
  -webkit-text-size-adjust: 100%;
  position: relative;
  margin: 10em auto;
  width: 850px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: rgb(250,250,250);
}
h {
  font-size: 14pt;
  color: #404040;
}
p {
  text-align: left;
  color: #404040;
}
a, a:link, a:visited {
  background-color:transparent;
  text-decoration:none;
  color: #0046a5;
}
div.block {
  padding: 1em 1em 1em 1em;
  border: 1px solid #ddd;
  background-color: #fff; 
}
</style>
</head>

<body>
<div class="block">
  <table>
    <tr>
      <td valign="middle">
        <img src="images/profile.jpg" style="float:left;padding-right:12px" width="150" />
      </td>
      <td valign="middle">
        <h>M.Shahzeb Khan Gul</h><br>
        <p>
          Research Associate at <a href="https://www.iis.fraunhofer.de/en/ff/amm/for/forschbewegtbildtechn/lichtfeld.html" target="_blank">Computational Imaging and Algorithms</a>,<br>
          Department of Audio and Media technologies, <a href="https://www.iis.fraunhofer.de/en.html" target="_blank">Fraunhofer IIS</a>,<br>
	  Ph.D. student and Early stage researcher for Marie Sklodowska-Curie project 'Real Vision'<br>
          muhammad.gul@iis.fraunhofer.de, shahxi31@gmail.com<br>
          <a href="https://scholar.google.com.tr/citations?user=sKqdTvoAAAAJ&hl=en" target="_blank">Google Scholar</a> | 
          <a href="https://linkedin.com/in/m-shahzeb-khan-61635793" target="_blank">Linkedin</a>
        </p>
      </td>
    </tr>
  </table>
</div>
<br>
<br>

<h>Bio</h>
<div class="block">
  <p>
    I am currently an Early Stage Researcher (ESR) in RealVision project received funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement No. 765911. <br>
	  <br>
    I have completed my undergraduate studies with a degree title of Bachelor of Engineering with a major in Electronics and a score of 85% (3.76 CGPA out of 4). My final year project “FPGA based Face Recognition System”, ICT R&D funded, broadened my concepts of image processing, digital development, and designing technique. I pursued my Master in Image processing and Deep learning from Istanbul Medipol University under the supervision of Prof. Dr. Bahadir K. Gunturk and graduated in May 2018. Currently, I am a pursuing Ph.D. research at Fraunhofer IIS under Dr. Ing. Joachim Keinert, working as a research associate in the Computational Imaging and Algorithms group.
  </p>
</div>
<br>
<br>

<h>Research Interests</h>
<div class="block">
  <p> Computer vision, Deep learning, and Plenoptic imaging.</p>
</div>
<br>
<br>

<h>Work Experience</h>
<div class="block">
  <table>
	<tr>
      <td valign="top"><p>Oct. 2018 - Present.&nbsp;</p></td>
      <td valign="top">
        <p>
          <b>Research Associate</b><br>
          Computation Imaging and Algorithms, Fraunhofer IIS, Erlangen (Germany)<br>
          - Light-field processing <br>
          - Novel view synthesis <br>
	  - 3D reconstruction <br>
        </p>
      </td>
  	<tr>
      <td valign="top"><p>Dec. 2017 - June. 2018.&nbsp;</p></td>
      <td valign="top">
        <p>
          <b>Digital Design and Verification Engineer</b><br>
          YongaTek, Istanbul (Turkey)<br>
          - RTL based design for the H.264 video decoder.<br>
          The decoder has been implemented in MATLAB successfully and its implementation over FPGA is
          ongoing.<br>
        </p>
      </td>
  	<tr>
      <td valign="top"><p>Aug. 2016 - June. 2018.&nbsp;</p></td>
      <td valign="top">
        <p>
          <b>Research Assistant</b><br>
          Istanbul Medipol University, Istanbul (Turkey)<br>
        </p>
      </td>
  	<tr>
      <td valign="top"><p>June. 2015 - July. 2016.&nbsp;</p></td>
      <td valign="top">
        <p>
          <b>R&D Engineer</b><br>
	  Genesis Solutions Pvt Ltd, Karachi (Pakistan)<br>
          - Working on multiple Embedded Platforms e.g. FPGA, ARM, Arduino and Microchip Controllers.<br>
          - Developed cross-platform GUI controls using C# code shared between Windows and different embedded targets.<br>          
        </p>
      </td>
  	<tr>
      <td valign="top"><p>Jan. 2015 - June. 2015.&nbsp;</p></td>
      <td valign="top">
        <p>
          <b>Lab Engineer</b><br>
          Pakistan Air-force Karachi Institute of Economics and Technology (PAF-KIET), Karachi (Pakistan)<br>
          - Conducting labs of undergraduate courses of Electrical Machines and Automation and Robotics.<br>
          - Founder and core member of Kiet Robotics Club (KRC).<br>
	  - Conducting robotics and embedded workshops under KRC.<br>
        </p>
      </td>
  </table>
</div>
<br>
<br>

<h>Publications</h><br>
	<h>Journals</h>
<div class="block">
  <img src="images/TIP18.png" style="float:left;padding-right:12px" height="150px" /><br style="clear:both" />
  <p>
    <b>M.Shahzeb Khan Gul</b>, Bahadir K. Gunturk,<br>
    Spatial and Angular Resolution Enhancement of Light Fields Using Convolutional Neural Networks,<br>
    IEEE Transactions on Image Processing ( Volume: 27, Issue: 5, May 2018 ).<br>
    <a href="http://ieeexplore.ieee.org/document/8259363/" target="_blank">Paper</a> | <a href="https://github.com/MShahzebKhan/Spatial-and-Angular-Resolution-Enhancement-of-Light-Fields-Using-Convolutional-Neural-Networks" target="_blank">Code</a>
  </p>
</div><br>
	<h>Conferences</h>
<div class="block">
  <img src="images/bmvc2019.PNG" style="float:left;padding-right:12px" height="150px" /><br style="clear:both" />
  <p>
    <b>M.Shahzeb Khan Gul</b>, Michel Baetz, Joachim Keinert,<br>
    Pixel-Wise Confidences for Stereo Disparities Using Recurrent Neural Networks,<br>
    British Machine Vision Conference (BMVC 2019), Cardiff, UK.<br>
    <a href="https://bmvc2019.org/wp-content/uploads/papers/0274-paper.pdf" target="_blank">Paper</a>
  </p>
</div><br>
	
<div class="block">
  <img src="images/ICME1.PNG" style="float:left;padding-right:12px" height="120px" /><br style="clear:both" />
  <p>
    <b>M.Shahzeb Khan Gul</b>, Thorsten Wolf, Michel Baetz, Matthias Ziegler, Joachim Keinert,<br>
    A high-resolution high dynamic range light-field dataset with an application to view-synthesis and tone-mapping,<br>
    IEEE International Conference on Multimedia and Expo (ICME 2020), London, UK || Virtual.<br>
    <a href="http://publica.fraunhofer.de/eprints/urn_nbn_de_0011-n-5993756.pdf" target="_blank">Paper</a> | <a href="https://fordatis.fraunhofer.de/handle/fordatis/158" target="_blank">Dataset</a>
  </p>
</div><br>

	<div class="block">
  <img src="images/ICME2.PNG" style="float:left;padding-right:12px" height="120px" /><br style="clear:both" />
  <p>
    Dingcheng Yue, <b>M.Shahzeb Khan Gul</b>, Michel Baetz, Joachim Keinert, Rafal Mantiuk,<br>
    A benckmark of light-field view-interpolation methods,<br>
    IEEE International Conference on Multimedia and Expo (ICME 2020), London, UK || Virtual.<br>
    <a href="https://www.cl.cam.ac.uk/research/rainbow/projects/lightfield-benchmark/lightfield_benchmark.pdf" target="_blank">Paper</a> | <a href="https://www.repository.cam.ac.uk/handle/1810/308349" target="_blank">Blender Dataset</a> | <a href="https://fordatis.fraunhofer.de/handle/fordatis/158" target="_blank">Real Dataset</a> | <a href="https://www.cl.cam.ac.uk/research/rainbow/projects/lightfield-benchmark/" target="_blank">Project Page</a>
  </p>
</div><br>

</body>
